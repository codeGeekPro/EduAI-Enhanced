"""
üéì EduAI Enhanced - Routes du Tuteur IA
API pour l'interaction avec le tuteur IA adaptatif multilingue
"""

from fastapi import APIRouter, HTTPException, Depends, UploadFile, File
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
from typing import List, Optional, Dict, Any
import asyncio
import json
import time
from datetime import datetime

from ...core.config import get_settings
from ...core.database import get_database, save_learning_analytics

settings = get_settings()
router = APIRouter()

# üìù Mod√®les de donn√©es

class ChatMessage(BaseModel):
    """Message dans une conversation avec le tuteur IA"""
    role: str  # "user" | "assistant" | "system"
    content: str
    timestamp: Optional[datetime] = None
    language: Optional[str] = "fr"
    emotion_detected: Optional[str] = None
    confidence_score: Optional[float] = None

class TutorRequest(BaseModel):
    """Requ√™te au tuteur IA"""
    message: str
    user_id: str
    session_id: Optional[str] = None
    subject: str = "general"
    language: str = "fr"
    difficulty_level: str = "intermediate"  # beginner, intermediate, advanced
    learning_style: str = "mixed"  # visual, auditory, kinesthetic, mixed
    context: Optional[Dict[str, Any]] = None

class TutorResponse(BaseModel):
    """R√©ponse du tuteur IA"""
    message: str
    session_id: str
    emotion_adaptation: Optional[str] = None
    suggested_exercises: Optional[List[Dict]] = None
    learning_insights: Optional[Dict] = None
    next_recommendations: Optional[List[str]] = None
    performance_feedback: Optional[Dict] = None

class LearningSession(BaseModel):
    """Session d'apprentissage"""
    session_id: str
    user_id: str
    subject: str
    started_at: datetime
    messages: List[ChatMessage] = []
    performance_metrics: Dict[str, Any] = {}
    emotion_timeline: List[Dict] = []

# üóÑÔ∏è Stockage temporaire des sessions (en production, utiliser Redis)
active_sessions: Dict[str, LearningSession] = {}

# ü§ñ Routes du Tuteur IA

@router.post("/chat", response_model=TutorResponse)
async def chat_with_tutor(request: TutorRequest):
    """
    üí¨ Converser avec le tuteur IA adaptatif
    
    Le tuteur s'adapte au style d'apprentissage, au niveau et √† l'√©tat √©motionnel
    """
    try:
        # G√©n√©rer un ID de session si n√©cessaire
        session_id = request.session_id or f"session_{int(time.time())}_{request.user_id}"
        
        # R√©cup√©rer ou cr√©er la session
        if session_id not in active_sessions:
            active_sessions[session_id] = LearningSession(
                session_id=session_id,
                user_id=request.user_id,
                subject=request.subject,
                started_at=datetime.now()
            )
        
        session = active_sessions[session_id]
        
        # Analyser l'√©motion du message (simulation)
        emotion_detected = await analyze_emotion(request.message, request.language)
        
        # Ajouter le message utilisateur √† l'historique
        user_message = ChatMessage(
            role="user",
            content=request.message,
            timestamp=datetime.now(),
            language=request.language,
            emotion_detected=emotion_detected.get("emotion"),
            confidence_score=emotion_detected.get("confidence")
        )
        session.messages.append(user_message)
        
        # G√©n√©rer la r√©ponse du tuteur IA
        tutor_response = await generate_tutor_response(
            request=request,
            session=session,
            emotion_state=emotion_detected
        )
        
        # Ajouter la r√©ponse √† l'historique
        assistant_message = ChatMessage(
            role="assistant",
            content=tutor_response.message,
            timestamp=datetime.now(),
            language=request.language
        )
        session.messages.append(assistant_message)
        
        # Sauvegarder les analytics
        await save_learning_analytics(request.user_id, {
            "event_type": "ai_interaction",
            "session_id": session_id,
            "subject": request.subject,
            "language": request.language,
            "emotion_detected": emotion_detected.get("emotion"),
            "message_length": len(request.message),
            "response_quality": "high"  # √Ä calculer en fonction des m√©triques
        })
        
        tutor_response.session_id = session_id
        return tutor_response
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erreur tuteur IA: {str(e)}")

@router.post("/voice-chat")
async def voice_chat_with_tutor(
    user_id: str,
    subject: str = "general",
    language: str = "fr",
    audio_file: UploadFile = File(...)
):
    """
    üé§ Interaction vocale avec le tuteur IA
    
    Traite l'audio avec Whisper, g√©n√®re une r√©ponse et la convertit en speech
    """
    try:
        # V√©rifier le format audio
        if not audio_file.filename.endswith(tuple(settings.supported_audio_formats)):
            raise HTTPException(
                status_code=400, 
                detail=f"Format audio non support√©. Utilisez: {settings.supported_audio_formats}"
            )
        
        # Lire le fichier audio
        audio_content = await audio_file.read()
        
        # Transcription avec Whisper (simulation)
        transcription = await transcribe_audio(audio_content, language)
        
        # Cr√©er une requ√™te de chat
        chat_request = TutorRequest(
            message=transcription["text"],
            user_id=user_id,
            subject=subject,
            language=language
        )
        
        # Obtenir la r√©ponse du tuteur
        tutor_response = await chat_with_tutor(chat_request)
        
        # Convertir la r√©ponse en audio avec TTS
        audio_response = await text_to_speech(
            text=tutor_response.message,
            language=language,
            voice_style="educational"
        )
        
        # Retourner l'audio comme streaming response
        return StreamingResponse(
            audio_response,
            media_type="audio/wav",
            headers={
                "Content-Disposition": "attachment; filename=tutor_response.wav",
                "X-Transcription": transcription["text"],
                "X-Session-ID": tutor_response.session_id
            }
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erreur chat vocal: {str(e)}")

@router.get("/session/{session_id}", response_model=LearningSession)
async def get_learning_session(session_id: str):
    """üìä R√©cup√©rer les d√©tails d'une session d'apprentissage"""
    if session_id not in active_sessions:
        raise HTTPException(status_code=404, detail="Session non trouv√©e")
    
    return active_sessions[session_id]

@router.get("/user/{user_id}/sessions")
async def get_user_sessions(user_id: str, limit: int = 10):
    """üìã R√©cup√©rer les sessions d'un utilisateur"""
    user_sessions = [
        session for session in active_sessions.values() 
        if session.user_id == user_id
    ]
    
    # Trier par date (plus r√©centes en premier)
    user_sessions.sort(key=lambda x: x.started_at, reverse=True)
    
    return {
        "user_id": user_id,
        "total_sessions": len(user_sessions),
        "sessions": user_sessions[:limit]
    }

@router.post("/session/{session_id}/feedback")
async def submit_session_feedback(
    session_id: str,
    feedback: Dict[str, Any]
):
    """‚≠ê Soumettre un feedback sur la session d'apprentissage"""
    if session_id not in active_sessions:
        raise HTTPException(status_code=404, detail="Session non trouv√©e")
    
    session = active_sessions[session_id]
    
    # Ajouter le feedback aux m√©triques de performance
    session.performance_metrics.update({
        "user_feedback": feedback,
        "feedback_timestamp": datetime.now(),
        "satisfaction_score": feedback.get("rating", 0)
    })
    
    # Sauvegarder dans la base de donn√©es
    await save_learning_analytics(session.user_id, {
        "event_type": "session_feedback",
        "session_id": session_id,
        "feedback": feedback
    })
    
    return {"status": "success", "message": "Feedback enregistr√© avec succ√®s"}

@router.get("/adaptive-insights/{user_id}")
async def get_adaptive_insights(user_id: str):
    """üß† Obtenir des insights adaptatifs pour personnaliser l'apprentissage"""
    try:
        # Analyser l'historique d'apprentissage de l'utilisateur
        user_sessions = [
            session for session in active_sessions.values() 
            if session.user_id == user_id
        ]
        
        if not user_sessions:
            return {
                "user_id": user_id,
                "insights": "Donn√©es insuffisantes pour g√©n√©rer des insights",
                "recommendations": [
                    "Commencez par une session d'introduction",
                    "Explorez diff√©rents sujets pour identifier vos pr√©f√©rences"
                ]
            }
        
        # Calculer les m√©triques d'apprentissage
        total_sessions = len(user_sessions)
        avg_session_length = sum(len(s.messages) for s in user_sessions) / total_sessions
        
        # Analyser les √©motions dominantes
        all_emotions = []
        for session in user_sessions:
            for message in session.messages:
                if message.emotion_detected:
                    all_emotions.append(message.emotion_detected)
        
        dominant_emotion = max(set(all_emotions), key=all_emotions.count) if all_emotions else "neutral"
        
        # Analyser les sujets pr√©f√©r√©s
        subject_counts = {}
        for session in user_sessions:
            subject_counts[session.subject] = subject_counts.get(session.subject, 0) + 1
        
        preferred_subject = max(subject_counts.items(), key=lambda x: x[1])[0] if subject_counts else "general"
        
        insights = {
            "user_id": user_id,
            "learning_profile": {
                "total_sessions": total_sessions,
                "avg_interaction_per_session": round(avg_session_length, 1),
                "dominant_emotion": dominant_emotion,
                "preferred_subject": preferred_subject,
                "engagement_level": "high" if avg_session_length > 5 else "medium"
            },
            "personalized_recommendations": [
                f"Continuez √† explorer {preferred_subject} - vous montrez de l'int√©r√™t !",
                f"Votre √©tat √©motionnel '{dominant_emotion}' sugg√®re un style d'apprentissage adaptatif",
                "Essayez les exercices interactifs pour maintenir l'engagement"
            ],
            "next_learning_paths": [
                {
                    "subject": preferred_subject,
                    "difficulty": "intermediate",
                    "estimated_duration": "15-20 minutes"
                }
            ]
        }
        
        return insights
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erreur g√©n√©ration insights: {str(e)}")

# üõ†Ô∏è Fonctions utilitaires

async def analyze_emotion(text: str, language: str) -> Dict[str, Any]:
    """Analyser l'√©motion dans un texte"""
    # Simulation - en r√©alit√©, utiliser un mod√®le de d√©tection d'√©motion
    emotions = ["happy", "sad", "frustrated", "excited", "confused", "confident", "neutral"]
    
    # Logique simple bas√©e sur des mots-cl√©s
    emotion_keywords = {
        "happy": ["super", "g√©nial", "parfait", "excellent", "great", "awesome"],
        "frustrated": ["difficile", "compliqu√©", "impossible", "nul", "hate", "difficult"],
        "confused": ["comprends pas", "confus", "quoi", "confused", "what", "huh"],
        "excited": ["wow", "incroyable", "amazing", "fantastic", "love"],
        "confident": ["facile", "s√ªr", "certain", "easy", "confident", "sure"]
    }
    
    text_lower = text.lower()
    detected_emotion = "neutral"
    confidence = 0.5
    
    for emotion, keywords in emotion_keywords.items():
        if any(keyword in text_lower for keyword in keywords):
            detected_emotion = emotion
            confidence = 0.8
            break
    
    return {
        "emotion": detected_emotion,
        "confidence": confidence,
        "available_emotions": emotions
    }

async def generate_tutor_response(
    request: TutorRequest,
    session: LearningSession,
    emotion_state: Dict[str, Any]
) -> TutorResponse:
    """G√©n√©rer une r√©ponse du tuteur IA adapt√©e"""
    
    # Adapter le ton selon l'√©motion d√©tect√©e
    emotion = emotion_state.get("emotion", "neutral")
    
    tone_adaptations = {
        "frustrated": "Je comprends que cela puisse √™tre frustrant. Prenons les choses √©tape par √©tape.",
        "confused": "Pas de souci, clarifions cela ensemble. Quelle partie vous pose le plus de probl√®me ?",
        "excited": "J'adore votre enthousiasme ! Continuons sur cette lanc√©e.",
        "confident": "Excellent ! Vous ma√Ætrisez bien. Pr√™t pour un d√©fi plus avanc√© ?",
        "sad": "L'apprentissage peut parfois sembler difficile, mais vous progressez vraiment bien."
    }
    
    # Construire la r√©ponse selon le contexte
    base_response = f"Concernant votre question sur {request.subject}: "
    
    # Ajouter l'adaptation √©motionnelle
    if emotion in tone_adaptations:
        emotion_adaptation = tone_adaptations[emotion]
        response = f"{emotion_adaptation} {base_response}"
    else:
        response = base_response
    
    # Simulation d'une r√©ponse √©ducative (en r√©alit√©, utiliser GPT-4)
    educational_responses = {
        "mathematics": "Les math√©matiques suivent des patterns logiques. Essayons de d√©composer le probl√®me...",
        "science": "La science nous aide √† comprendre le monde qui nous entoure. Observons ce ph√©nom√®ne...",
        "history": "L'histoire nous enseigne les le√ßons du pass√©. Cette p√©riode √©tait caract√©ris√©e par...",
        "literature": "La litt√©rature exprime la beaut√© du langage. Analysons ce texte ensemble..."
    }
    
    subject_response = educational_responses.get(request.subject, "C'est une excellente question ! Explorons cela ensemble.")
    response += subject_response
    
    # G√©n√©rer des exercices sugg√©r√©s
    suggested_exercises = [
        {
            "type": "quiz",
            "title": f"Quiz rapide sur {request.subject}",
            "duration": "5 minutes",
            "difficulty": request.difficulty_level
        },
        {
            "type": "interactive",
            "title": "Exercice pratique interactif", 
            "duration": "10 minutes",
            "style": request.learning_style
        }
    ]
    
    # Insights d'apprentissage
    learning_insights = {
        "interaction_count": len(session.messages),
        "session_duration": (datetime.now() - session.started_at).seconds,
        "emotion_trend": emotion,
        "engagement_level": "high" if len(session.messages) > 3 else "building"
    }
    
    return TutorResponse(
        message=response,
        session_id=session.session_id,
        emotion_adaptation=tone_adaptations.get(emotion),
        suggested_exercises=suggested_exercises,
        learning_insights=learning_insights,
        next_recommendations=[
            f"Explorez plus de {request.subject}",
            "Essayez un exercice pratique",
            "Partagez vos questions"
        ]
    )

async def transcribe_audio(audio_content: bytes, language: str) -> Dict[str, Any]:
    """Transcrire l'audio en texte avec Whisper"""
    # Simulation - en r√©alit√©, utiliser OpenAI Whisper API
    await asyncio.sleep(1)  # Simuler le traitement
    
    return {
        "text": "Bonjour, peux-tu m'aider avec les math√©matiques ?",
        "language": language,
        "confidence": 0.95,
        "duration": 3.5
    }

async def text_to_speech(text: str, language: str, voice_style: str = "educational"):
    """Convertir le texte en parole avec ElevenLabs"""
    # Simulation - en r√©alit√©, utiliser ElevenLabs API
    await asyncio.sleep(1)  # Simuler la g√©n√©ration
    
    # Retourner un g√©n√©rateur pour l'audio (simulation)
    async def generate_audio():
        yield b"fake_audio_data_here"  # En r√©alit√©, les donn√©es audio r√©elles
    
    return generate_audio()

# Middleware pour la gestion des erreurs
@router.exception_handler(Exception)
async def tutor_exception_handler(request, exc):
    return {"error": "Erreur du tuteur IA", "detail": str(exc), "status": "error"}
